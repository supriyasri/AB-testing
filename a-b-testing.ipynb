{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# DATASET TAKEN FROM https://www.kaggle.com/shweta112/a-b-testing-analysis\n\ndf=pd. read_csv('/kaggle/input/ab-testing/ab_data.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:18:19.722252Z","iopub.execute_input":"2022-01-07T03:18:19.722532Z","iopub.status.idle":"2022-01-07T03:18:20.385386Z","shell.execute_reply.started":"2022-01-07T03:18:19.722501Z","shell.execute_reply":"2022-01-07T03:18:20.384569Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:17:24.188881Z","iopub.execute_input":"2022-01-07T03:17:24.189183Z","iopub.status.idle":"2022-01-07T03:17:24.195776Z","shell.execute_reply.started":"2022-01-07T03:17:24.189149Z","shell.execute_reply":"2022-01-07T03:17:24.193514Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-07T02:36:15.601187Z","iopub.execute_input":"2022-01-07T02:36:15.601614Z","iopub.status.idle":"2022-01-07T02:36:15.610623Z","shell.execute_reply.started":"2022-01-07T02:36:15.601583Z","shell.execute_reply":"2022-01-07T02:36:15.610078Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:18:28.807161Z","iopub.execute_input":"2022-01-07T03:18:28.807466Z","iopub.status.idle":"2022-01-07T03:18:28.820140Z","shell.execute_reply.started":"2022-01-07T03:18:28.807431Z","shell.execute_reply":"2022-01-07T03:18:28.819327Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.info()\n#294477 entries are present ( check for duplicates)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:19:22.950454Z","iopub.execute_input":"2022-01-07T03:19:22.951231Z","iopub.status.idle":"2022-01-07T03:19:23.076509Z","shell.execute_reply.started":"2022-01-07T03:19:22.951186Z","shell.execute_reply":"2022-01-07T03:19:23.075392Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:19:38.202970Z","iopub.execute_input":"2022-01-07T03:19:38.203235Z","iopub.status.idle":"2022-01-07T03:19:38.208845Z","shell.execute_reply.started":"2022-01-07T03:19:38.203207Z","shell.execute_reply":"2022-01-07T03:19:38.208067Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.size","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:19:44.300484Z","iopub.execute_input":"2022-01-07T03:19:44.300785Z","iopub.status.idle":"2022-01-07T03:19:44.306619Z","shell.execute_reply.started":"2022-01-07T03:19:44.300754Z","shell.execute_reply":"2022-01-07T03:19:44.305615Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df['group'],df['landing_page'])","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:19:51.195201Z","iopub.execute_input":"2022-01-07T03:19:51.195470Z","iopub.status.idle":"2022-01-07T03:19:51.309171Z","shell.execute_reply.started":"2022-01-07T03:19:51.195440Z","shell.execute_reply":"2022-01-07T03:19:51.308241Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"\ncheck for duplicate values \n\n# have the ability to remove duplicates from dataset before going to consider sampling","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df['user_id'].unique()\n# unique values are displayed here","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:19:58.502759Z","iopub.execute_input":"2022-01-07T03:19:58.503263Z","iopub.status.idle":"2022-01-07T03:19:58.522885Z","shell.execute_reply.started":"2022-01-07T03:19:58.503222Z","shell.execute_reply":"2022-01-07T03:19:58.522076Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"session_count=df['user_id'].value_counts(ascending=False)\nprint(session_count.head(20))\n# gives idea of how many times the given user-id is present","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:20:04.063276Z","iopub.execute_input":"2022-01-07T03:20:04.063821Z","iopub.status.idle":"2022-01-07T03:20:04.107173Z","shell.execute_reply.started":"2022-01-07T03:20:04.063779Z","shell.execute_reply":"2022-01-07T03:20:04.106298Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\nmulti_users = session_count[session_count > 1].count()\n\nprint(f'There are {multi_users} users that appear multiple times in the dataset')\n\n# could analyze the count of value_count that are greater than 1","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:20:35.173359Z","iopub.execute_input":"2022-01-07T03:20:35.173641Z","iopub.status.idle":"2022-01-07T03:20:35.179844Z","shell.execute_reply.started":"2022-01-07T03:20:35.173609Z","shell.execute_reply":"2022-01-07T03:20:35.179036Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# since 3894 users are repeated, we can remove those counts before going ahead \n# for sampling\nusers_to_drop=session_count[session_count >1].index\ndf1=df[~df['user_id'].isin(users_to_drop)]\n\nprint(f'The updated dataset now has {df1.shape[0]} entries')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:20:54.695905Z","iopub.execute_input":"2022-01-07T03:20:54.696764Z","iopub.status.idle":"2022-01-07T03:20:54.725713Z","shell.execute_reply.started":"2022-01-07T03:20:54.696717Z","shell.execute_reply":"2022-01-07T03:20:54.724900Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Since dataset is removed from duplicate values, let's step into Sampling \nconsidering simple random sampling ","metadata":{}},{"cell_type":"code","source":"control_sample = df1[df1['group'] == 'control'].sample(n=required_n,random_state=22)\ntreatment_sample=df1[df1['group']=='treatment'].sample(n=required_n,random_state=22)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:23:49.780470Z","iopub.execute_input":"2022-01-07T03:23:49.781070Z","iopub.status.idle":"2022-01-07T03:23:49.913623Z","shell.execute_reply.started":"2022-01-07T03:23:49.781015Z","shell.execute_reply":"2022-01-07T03:23:49.912990Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"control_sample.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:23:53.821264Z","iopub.execute_input":"2022-01-07T03:23:53.821541Z","iopub.status.idle":"2022-01-07T03:23:53.833176Z","shell.execute_reply.started":"2022-01-07T03:23:53.821510Z","shell.execute_reply":"2022-01-07T03:23:53.832362Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"ab_test = pd.concat([control_sample, treatment_sample], axis=0)\nab_test.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:23:59.641762Z","iopub.execute_input":"2022-01-07T03:23:59.642037Z","iopub.status.idle":"2022-01-07T03:23:59.648646Z","shell.execute_reply.started":"2022-01-07T03:23:59.642009Z","shell.execute_reply":"2022-01-07T03:23:59.647791Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"ab_test","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:24:07.486354Z","iopub.execute_input":"2022-01-07T03:24:07.486619Z","iopub.status.idle":"2022-01-07T03:24:07.501185Z","shell.execute_reply.started":"2022-01-07T03:24:07.486590Z","shell.execute_reply":"2022-01-07T03:24:07.500200Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Step 1- Design hypothesis","metadata":{}},{"cell_type":"code","source":"# Packages imports\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nimport statsmodels.stats.api as sms\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom math import ceil\n\n%matplotlib inline\n\n# Some plot styling preferences\nplt.style.use('seaborn-whitegrid')\nfont = {'family' : 'Helvetica',\n        'weight' : 'bold',\n        'size'   : 14}\n\nmpl.rc('font', **font)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:21:55.144178Z","iopub.execute_input":"2022-01-07T03:21:55.144451Z","iopub.status.idle":"2022-01-07T03:21:56.313559Z","shell.execute_reply.started":"2022-01-07T03:21:55.144421Z","shell.execute_reply":"2022-01-07T03:21:56.312600Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"effect_size = sms.proportion_effectsize(0.13, 0.15) # Calculating effect size based on our expected rates\n\nrequired_n = sms.NormalIndPower().solve_power(\n    effect_size, \n    power=0.8, \n    alpha=0.05, \n    ratio=1\n    )                              # Calculating sample size needed\n\nrequired_n = ceil(required_n)     # Rounding up to next whole number                          \n\nprint(required_n)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:22:12.901940Z","iopub.execute_input":"2022-01-07T03:22:12.902487Z","iopub.status.idle":"2022-01-07T03:22:12.921799Z","shell.execute_reply.started":"2022-01-07T03:22:12.902452Z","shell.execute_reply":"2022-01-07T03:22:12.920984Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"3. Visualising the results\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Calculate the converted points and visualize for both control and treatment variant","metadata":{}},{"cell_type":"code","source":"conversion_rates=ab_test.groupby('group')['converted']\n\nstd_p= lambda x:np.std(x,ddof=0)     # Std. deviation of the proportion\nse_p= lambda x:stats.sem(x, ddof=0)  # Std. error of the proportion\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:24:26.890779Z","iopub.execute_input":"2022-01-07T03:24:26.891075Z","iopub.status.idle":"2022-01-07T03:24:26.896365Z","shell.execute_reply.started":"2022-01-07T03:24:26.891044Z","shell.execute_reply":"2022-01-07T03:24:26.895393Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"conversion_rates=conversion_rates.agg([np.mean,std_p,se_p])\nconversion_rates.columns = ['conversion_rate', 'std_deviation', 'std_error']\n\nconversion_rates.style.format('{:.3f}')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:24:51.331939Z","iopub.execute_input":"2022-01-07T03:24:51.332528Z","iopub.status.idle":"2022-01-07T03:24:51.411817Z","shell.execute_reply.started":"2022-01-07T03:24:51.332478Z","shell.execute_reply":"2022-01-07T03:24:51.411023Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"Judging by the stats above, it does look like our two designs performed very similarly, with our new design performing slightly better, approx. 12.3% vs. 12.6% conversion rate.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.barplot(x=ab_test['group'],y=ab_test['converted'],ci=False)\n\nplt.ylim(0,0.17)\nplt.title('Conversion rate by group')\nplt.xlabel('Group')\nplt.ylabel('Converted(proportion)')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:43:32.125709Z","iopub.execute_input":"2022-01-07T03:43:32.126371Z","iopub.status.idle":"2022-01-07T03:43:32.479146Z","shell.execute_reply.started":"2022-01-07T03:43:32.126320Z","shell.execute_reply":"2022-01-07T03:43:32.478202Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"The conversion rates for our groups are indeed very close. Also note that the conversion rate of the control group is lower than what we would have expected given what we knew about our avg. conversion rate (12.3% vs. 13%). This goes to show that there is some variation in results when sampling from a population.\n\nSo... the treatment group's value is higher. Is this difference statistically significant?","metadata":{}},{"cell_type":"markdown","source":"4- Test the hypothesis\n Since we have a very large sample, we can use the normal approximation for calculating our -value (i.e. z-test).","metadata":{}},{"cell_type":"code","source":"from statsmodels.stats.proportion import proportions_ztest, proportion_confint\n","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:45:27.040402Z","iopub.execute_input":"2022-01-07T03:45:27.040676Z","iopub.status.idle":"2022-01-07T03:45:27.044965Z","shell.execute_reply.started":"2022-01-07T03:45:27.040647Z","shell.execute_reply":"2022-01-07T03:45:27.044315Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"control_results = ab_test[ab_test['group'] == 'control']['converted']\ntreatment_results = ab_test[ab_test['group'] == 'treatment']['converted']","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:45:54.348361Z","iopub.execute_input":"2022-01-07T03:45:54.349147Z","iopub.status.idle":"2022-01-07T03:45:54.362627Z","shell.execute_reply.started":"2022-01-07T03:45:54.349096Z","shell.execute_reply":"2022-01-07T03:45:54.361920Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"n_con = control_results.count()\nn_treat = treatment_results.count()\nsuccesses = [control_results.sum(), treatment_results.sum()]\nnobs = [n_con, n_treat]\n\nz_stat, pval = proportions_ztest(successes, nobs=nobs)\n(lower_con, lower_treat), (upper_con, upper_treat) = proportion_confint(successes, nobs=nobs, alpha=0.05)\n\nprint(f'z statistic: {z_stat:.2f}')\nprint(f'p-value: {pval:.3f}')\nprint(f'ci 95% for control group: [{lower_con:.3f}, {upper_con:.3f}]')\nprint(f'ci 95% for treatment group: [{lower_treat:.3f}, {upper_treat:.3f}]')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-07T03:51:11.959212Z","iopub.execute_input":"2022-01-07T03:51:11.959636Z","iopub.status.idle":"2022-01-07T03:51:11.968767Z","shell.execute_reply.started":"2022-01-07T03:51:11.959606Z","shell.execute_reply":"2022-01-07T03:51:11.967923Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"CONCLUSION\n\n# here p-value is 0.732, a lot greater than alpha value (0.05%). Hence we cannot reject null hypothesis.\n\nAdditionally, if we look at the confidence interval for the treatment group ([0.116, 0.135], i.e. 11.6-13.5%) we notice that:\n\nIt includes our baseline value of 13% conversion rate\nIt does not include our target value of 15% (the 2% uplift we were aiming for)\nWhat this means is that it is more likely that the true conversion rate of the new design is similar to our baseline, rather than the 15% target we had hoped for. This is further proof that our new design is not likely to be an improvement on our old design, and that unfortunately we are back to the drawing board!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}